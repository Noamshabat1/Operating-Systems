no.amshabat1, tzachiel
Student Noam Shabat (206515579), Tzachi Elya (313223687)
EX: 1

FILES:
- memory_latency.cpp: Implements required functions and the main function for OS2024 ex1.
- Makefile: Builds the executable and cleans the environment.
- README: Contains student information and theoretical question answers.
- lscpu.png: Output of the lscpu command on CSE labs computers.
- results.png: Graph showing latency differences between random and sequential memory access.
- PAGE_SIZE.png: the output of the getconf PAGE_SIZE command on CSE labs computers.

REMARKS:

ANSWERS:
Assignment 1:
1. Creates a directory named "Welcome" with specific access permissions.
2. Creates three files inside this directory ("Welcome", "To" & "OS-2024"), each with specific content:
   - "Welcome" containSs a message about a previous reading - " no.amshabat1\nIf you haven't read".
     writes 81 bytes of data to it, and then closes it.".
   - "To" contains the phrase "Start exercises early!"
   - "OS-2024" contains the phrase "Good luck!"
3. Deletes the three files and removes the directory after writing to them.
4. Exiting the program with a success status.

Assignment 2:
We can observe that as the array size increases, the latency for random access increases significantly, while
the latency for sequential access remains relatively constant. This phenomenon can be explained by the way
modern memory systems and caches operate, as discussed in class and with the TA.

Modern computers utilize a hierarchical memory system, consisting of small, fast caches (L1, L2, L3) near the
CPU, and larger, slower main memory (RAM) further away.

The Sequential access gains from spatial locality, which means that consecutive memory accesses are located
close to each other in memory. This allows efficient use of cache lines, which typically fetch a block of
contiguous memory addresses. As a result, sequential access remains within the fast cache for a longer period,
keeping latency low even as the array size increases.

On the other hand, random access lacks the spatial locality that sequential access has. Each access can jump
to any location in the array. As the array size grows, the chance of the randomly accessed data being in
the fast cache decreases. This leads to more cache misses, which require fetching data from the slower options.

to conclude, the increasing latency for random access compared to the stable latency for sequential access
reflects the differing impacts of cache effectiveness and the memory hierarchy on these two access patterns.

Bonus:
After L3, there is a page table within L3 that enables quick reading of the instruction address in memory,
and therefore the graph continues to grow at the same rate.
When reaching the threshold, we start to see two reads from the RAM, and this is reflected slightly in the edge of
our graph, which grows at a faster rate.
